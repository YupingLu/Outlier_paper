%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
The Atmospheric Radiation Measurement (ARM) user facility was founded by
the U.S. Department of Energy (DOE) in 1989 \cite{ARM}. Since then, its
aim is to be the platform for the observation and study of Earth's
climate. ARM facility collects large volume of datasets from instruments deployed in
different ground stations across the globe \cite{stokes1994atmospheric}.
The ARM Data Center (ADC) is responsible for ingesting the collected data and
creating high level scientific data products for distribution and
dissemination to scientific research community, especially to inform and
improve the representation of atmospheric, cloud and aerosols
processes in global climate models (GCMs)
\cite{gaustad2014scientific}. They also develop a large number of 
high level data products, also
called ``Value Added Products" (VAPs), quality of which are highly dependent on the
correctness of the raw data. Data are transferred from individual site
to ADC in a streaming near-real-time fashion and the raw data is
ingested, processed to produce VAPs and made available to users via a
web-based data discovery interface with a lag time of less than an hour.
Along with expediency, it is also essential to identify, address, and 
communicate any noise and outliers in the data to maintain high data quality.
Thus an effective and efficient outlier and noise detection
is crucial for ARM to provide scientific users with high quality data
for research.

Outlier detection, also called anomaly detection or intrusion detection,
is a common task in many application domains that include time
series data, streaming data, distributed data, spatio-temporal
data, and network data \cite{gupta2014outlier}. Temporal data is
a broad concept that includes commercial transactions, sensor
data, astronomy data, computer network traffic, medical records,
judicial records, social network data and many others. Common
techniques for outlier detection include signal processing,
classification, clustering, nearest neighbor, density,
statistical, information theory, spectral decomposition, and
visualization. Among all these techniques, time series data
outlier detection and temporal network outlier detection are
especially useful for ARM data.

Outlier detection in time series data was first studied by Fox in 1972
\cite{fox1972outliers}. Common types of outliers are additive outliers,
level shifts, temporary changes, and innovative outliers. One common
approach is the discriminative method which is based on a similarity
function. For example, the normalized longest common subsequence
(NLCS) is a similarity measurement widely used in the field of data
mining \cite{budalakoti2009anomaly, chandola2008comparative,
sequeira2002admit}. Commonly used clustering methods such as
K-means \cite{macqueen1967some}, dynamic clustering
\cite{sequeira2002admit}, single-linkage clustering
\cite{portnoy2001intrusion}, principal component analysis (PCA)
\cite{gupta2013context}, and self-organizing map (SOM)
\cite{gonzalez2003anomaly} are also popular. The choice of the
clustering algorithm depends on the problem itself as each has
different size and complexity. Researchers have also tried supervised
methods such as neural networks \cite{dasgupta2000comparison},
support vector machines (SVMs) \cite{li2006motion}, and decision
trees \cite{kang2005learning} to detect outliers.

Different from the methods mentioned above, window-based detection 
breaks the time series data into overlapping subsequences with fixed
window size \cite{cheboli2010anomaly}. Each window is assigned an
anomaly score, and then a final score for the times series data is
calculated by aggregating the window scores. Subspace based analysis for
univariate time series data is similar to window-based detection. The
subspace based transformation is to convert a univariate time series
into a multivariate time series with fixed window size. It then
transforms the multivariate time series back to univariate time series.
Singular Spectrum Analysis is a widely used algorithm for such problem
\cite{golyandina2013singular}.

ARM data also belongs to the class of temporal data as we can sequentially create a
time series of network changes or graph snapshots at different periods.
Each period forms a graph snapshot using various graph distance metrics
from a set of nodes. Many challenges exist for outlier detection for
temporal data. First, the algorithm or model needs to be chosen
carefully as the properties of each data and network are different.
Second, the temporal data has space and time dimensions which make it
complex to analysis. Third, its scale is massive, and efficient algorithm
is crucial for fast outlier detection. One common problem for temporal
data is to detect outlier graph snapshots from a series of graph snapshots
in temporal networks. Spearman's correlation coefficient is a good
candidate for such problem. It is the rank correlation between two
sorted lists of graph vertices which are ordered by PageRank or other
properties \cite{papadimitriou2010web}. Similar to Spearman's
correlation coefficient, Pearson correlation coefficient, which is explained 
in detail later and mutual information are also commonly used. 
Jaccard similarity, graph edit distance, spectral distance and entropy 
distance are few other commonly proven metrics in temporal network outlier detection.
Jaccard similarity is the size of intersection vertex set
divided by the size of union vertex set \cite{jay2012systematic}. Graph
edit distance describes the necessary changes to make graph $G_1$
isomorphic to graph $G_2$. It can defined as $d(G_1, G_2) = |V_{G_1}| +
|V_{G_2}| - 2|V_{G_1} \cap V_{G_2}| + |E_{G_1}| + |E_{G_2}| - 2|E_{G_1}
\cap E_{G_2}|$ \cite{papadimitriou2010web}. The spectral distance is the
difference between the adjacency spectrum of graph $G_1$ and $G_2$,
written as $\sigma(G_1, G_2) =
\displaystyle\sum_{i=1}^{n}|\lambda_i(G_1) - \lambda_i(G_2)|$
\cite{jovanovic2012spectral}. Entropy distance is defined by
the entropy-like measurement between two graphs
\cite{pincombe2005anomaly}.

A number of approaches have been developed in literature for temporal outlier detection,
especially for environmental sensor data. Birant et al.
\cite{kut2006spatio} discovered high wave heights values as outliers 
while studying the wave height values from the east of
the Mediterranean Sea, the Marmara Sea, the Black sea, and the
Aegean Sea. Hill et al. \cite{hill2007real, hill2010anomaly}
filtered out measurement errors in the wind speed data stream from
Water and Environmental Research Systems (WATERS) Network Corpus
Christi Bay testbed with dynamic Bayesian networks. Drosdowsky et
al. \cite{drosdowsky1993analysis} found anomalies from Australian
district rainfall using rotated PCA. Wu et al. \cite{wu2010spatio}
detected precipitation outlier events while working on South
American precipitation data set. Sun et al.
\cite{yuxiang2005detecting} extracted locations which always have
different temperature from their surroundings by exploring the
South China area dataset from 1992 to 2002.

Within ARM program, the Data Quality Office (DQO) is charged with 
inspecting and assessing approximately 5,000 data fields on a daily 
to weekly basis. The objective of DQO is to quickly identify data 
anomalies and report them to site operators and instrument mentors 
so that corrective actions can be performed and thereby minimize the 
amount of unacceptable data collected. With focus on quick near real-time 
assessment of data, process relies heavily on univariate analysis and lacks 
rigorous detection of outliers. Objective of this study was to develop
efficient and rigorous  outlier detection technique for ARM time series
data using univariate, multivariate and time series statistical
techniques.
