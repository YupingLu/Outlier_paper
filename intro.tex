%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
The Atmospheric Radiation Measurement (ARM) user facility was founded by the U.S. Department of Energy (DOE) in 1989 \cite{ARM}. Since then, its aim is to be the platform for the observation and study of Earth's climate. Huge ARM datasets are collected from instruments deployed in different ground stations across the globe \cite{stokes1994atmospheric}. The ARM Data Center is responsible for ingesting the collected data and creating high level scientific data products for distribution and the improvement of global climate models (GCMs) \cite{gaustad2014scientific}. These high level data products, also called ``Value Added Products" (VAPs), are highly dependent on the correctness of the raw data. Thus it is crucial to detect outliers in the raw data and correct them.

% The general definition of outlier detection and their types.
Outlier detection, also called anomaly detection or intrusion detection, is a common task in many application domains which include time series data, streaming data, distributed data, spatio-temporal data, and network data \cite{gupta2014outlier}. Temporal data is a broad concept which include commercial transactions, sensor data, astronomy data, computer network traffic, medical records, judicial records, social network data and many others. Common techniques for outlier detection include signal processing, classification, clustering, nearest neighbor, density, statistical, information theory, spectral decomposition, and visualization. Among all these techniques, time series data outlier detection and temporal network outlier detection are especially useful for ARM data.

% Outlier detection for time series data
Outlier detection in time series data was first studied by Fox in 1972 \cite{fox1972outliers}. Common types of outliers are additive outliers, level shifts, temporary changes, and innovative outliers. One common approach is the discriminative method which is based on a similarity function. For example, the normalized longest common subsequence (NLCS) is a similarity measurement widely used in the field of data mining \cite{budalakoti2009anomaly, chandola2008comparative, sequeira2002admit}. Commonly used clustering methods such as K-means \cite{macqueen1967some}, dynamic clustering \cite{sequeira2002admit}, single-linkage clustering \cite{portnoy2001intrusion}, principal component analysis (PCA) \cite{gupta2013context}, and self-organizing map (SOM) \cite{gonzalez2003anomaly} are also popular. The choice of the clustering algorithm depends on the problem itself as each has different size and complexity. Three unsupervised parametric models, finite state automata (FSA), Markov models, and Hidden Markov Models (HMMs), are often seen in outlier detection as well. An outlier is detected if the FSA in the current state could not reach the final state \cite{chandola2008comparative}. The history size in the Markov model could be either fixed or flexible. HMMs are easy to interpret but not function well with big datasets \cite{chandola2008comparative}. Researchers also tried supervised methods such as neural networks \cite{dasgupta2000comparison}, support vector machines (SVMs) \cite{li2006motion}, and decision trees \cite{kang2005learning} to detect outliers.

% window based methods
Different from the methods mentioned above, window-based detection is breaking the time series data into overlapping subsequences with fixed window size \cite{cheboli2010anomaly}. Each window is assigned an anomaly score, and then a final score for the times series data is calculated by aggregating the window scores. Subspace based analysis for univariate time series data is similar to window-based detection. The subspace based transformation is to convert a univariate time series into a multivariate time series with fixed window size. It then transforms the multivariate time series back to univariate time series. Singular Spectrum Analysis is a good example of this idea \cite{golyandina2013singular}.

% Outliers detection for temporal networks: graph, community etc. 
ARM data also belongs to temporal data as we can sequentially create a time series of network changes or graph snapshots at different periods. Each period forms a graph snapshot using various graph distance metrics from a set of nodes. Many challenges exist for outlier detection for temporal data. First, the algorithm or model needs to be chosen carefully as the properties of each data and network are different. Second, the temporal data has space and time dimensions which make it complex to analysis. Third, its scale is massive and efficient algorithm is crucial for fast outlier detection. One common problem for temporal data is to detect outlier graph snapshots from a series graph snapshots in temporal networks. Spearman's correlation coefficient is a good candidate for such problem. It is the rank correlation between two sorted lists of graph vertices which are ordered by PageRank or other properties \cite{papadimitriou2010web}. Similar to Spearman's correlation coefficient, Pearson correlation coefficient is also commonly used. Jaccard similarity is the size of intersection vertex set divided by the size of union vertex set \cite{jay2012systematic}. Graph edit distance describes the necessary changes to make graph $G_1$ isomorphic to graph $G_2$. It can defined as $d(G_1, G_2) = |V_{G_1}| + |V_{G_2}| - 2|V_{G_1} \cap V_{G_2}| + |E_{G_1}| + |E_{G_2}| - 2|E_{G_1} \cap E_{G_2}|$ \cite{papadimitriou2010web}. The spectral distance is the difference between the adjacency spectrum of graph $G_1$ and $G_2$, written as $\sigma(G_1, G_2) = \displaystyle\sum_{i=1}^{n}|\lambda_i(G_1) - \lambda_i(G_2)|$ \cite{jovanovic2012spectral}. Entropy distance is defined by the entropy-like measurement between two graphs \cite{pincombe2005anomaly}. All these metrics are also common seen in temporal network outlier detection.

% Application of outlier detection environmental sensor data
Many applications are available for temporal outlier detection, especially for environmental sensor data. Birant et al. \cite{kut2006spatio} discovered locations with high wave heights are outliers while studying the wave height values from the east of the Mediterranean Sea, the Marmara Sea, the Black sea, and the Aegean Sea. Hill et al. \cite{hill2007real, hill2010anomaly} filtered out measurement errors in the wind speed data stream from Water and Environmental Research Systems (WATERS) Network Corpus Christi Bay testbed with dynamic Bayesian networks. Drosdowsky et al. \cite{drosdowsky1993analysis} found anomalies from Australian district rainfall using rotated PCA. Wu et al. \cite{wu2010spatio} detected precipitation outlier events while working on South American precipitation data set. Sun et al. \cite{yuxiang2005detecting} extracted locations which always have different temperature from their surroundings by exploring the South China area dataset from 1992 to 2002.


